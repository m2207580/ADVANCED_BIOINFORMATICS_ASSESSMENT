---
title: "Advanced Bioinformatics 2023 assessment"
author: "m2207580"
date: "2023-04-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# GENERAL R/Rstudio ASSESSMENT

## 3.1. Write an expression in the code snippet to evaluate the sum of all integers between 5 and 55.
```{r}
x <- c(5:55); sum (x)
```
## 3.2. Write a function called sumfun with one input parameter, called n, that calculates the sum of all integers between 5 and n. 
```{r}
sumfun <- function(n) {sum(5:n)}
```
Use the function to do the calculation for n = 10, n = 20, and n = 100 and present the results.
```{r}
sumfun(10)
sumfun(20)
sumfun(100)
```
## 3.3. Write an R script using a for loop to calculate and print out the first 12 entries of the Fibonacci series. 
```{r}
n <- 12
fib <- numeric(n)
fib[1] <- 1 # fib of the first element is 1
fib[2] <- 1 # fib of the second element is 1
for (i in 3:n)
{
  fib[i] <- fib[i-1]+fib[i-2] 
}
print(fib)
```

## 3.4. With the mtcars dataset bundled with R, use ggplot to generate a box of miles per gallon (in the variable mpg) as a function of the number of gears (in the variable gear). Use the fill aesthetic to colour bars by number of gears.
```{r}
library(ggplot2)
ggplot(data = mtcars, aes(x= as.factor(gear), y= mpg)) + geom_boxplot(aes(fill= as.factor(gear) )) + ggtitle(" Box plot of Miles per gallon(mpg) as a function of gears")
```

## 3.5. Using the cars dataset and the function lm, fit a linear relationship between speed and breaking distance in the variable distance. 
```{r}
y <- cars $dist; x <- cars $speed ; # set the dependant and independent variable
model <- lm(formula = "y ~ x")
```

What are the fitted slope and intercept of the line, and their standard errors? What are the units used for the variables in the dataset?
```{r}
summary(model)
```
These stats give us the answers:
Fitted slope=3.9324
Intercept = -17.579
Standard errors ( 6.7584,0.4155)
Speed units = milesperhour breaking distance = feet

## 3.6. Use ggplot to plot the data points from the previous task and the linear fit.
```{r}
library(ggplot2)
ggplot_1.0 <- ggplot(data = cars, aes(x= speed, y=dist)) + geom_point() + geom_smooth(method = "lm",formula = "y ~ x") + ggtitle ("Linear model of the relationship between breaking distance(dist) and speed")+ xlab("speed(milesperhour)")+ ylab("dist(feet)")
ggplot_1.0
```

## 3.7.Now use linear regression (lm) to estimate the average reaction time for the driver to start breaking (in seconds). To simplify matters you may assume that once breaking commences, breaking distance is proportional to the square of the speed. Explain the steps in your analysis. Do you get reasonable results? Finally, use ggplot to plot the data points and the fitted relationship.
```{r}
# Assign the variable "break_dist" to breaking distance, which is the distance in miles    
    break_dist <- cars$dist* 0.000189 # converting distance to miles by multiplying by the value of one foot in miles
# Create a variable "speed_m_per_h" for speed in miles per hour
    speed_m_per_h <- cars $speed^2  #Since breaking distance is proportional to the square of speed, square the value of speed 
  lm(formula = break_dist ~ speed_m_per_h) # to create the linear model
```

```{r}
#From the model, slope is equal to half the average reaction time, if speed and distance are constant
    react_time <- 2.438e-05*2 # Reaction time is therefore equal to two times the value of the slope react_time
    #Converting reaction time in hours to seconds
    coverted_react_time <- react_time/3600
    coverted_react_time
```
The answer obtained is not reasonable, since there is a negative reaction time

```{r}
regression_breaking_dist_speed <- ggplot(data = cars, aes(speed_m_per_h, break_dist))+ geom_point() + geom_smooth(method = "lm", formula = break_dist ~ speed_m_per_h)+ggtitle("Regression model between breaking distance and speed")
regression_breaking_dist_speed
```


# RNA-seq ASSESSMENT
## 3.8. Read in count data and sample description
```{r}
all_counts <- read.csv(file = "~/MASTER/Advanced bioinformatics/ASSIGNMENT/RNAseq/exercise1_counts.csv", header = T, row.names = 1) #read the count information in the CSV file
head(all_counts)
```
```{r}
sam_des <- read.table("~/MASTER/Advanced bioinformatics/ASSIGNMENT/RNAseq/exercise1_sample_description.info", sep = "\t", header = TRUE) #Read the sample description that we manually generated 
head(sam_des)
```
## 3.9. Create col_data and check dimensions
```{r}
col_data <- data.frame(sample = sam_des$sample, condition = sam_des$condition, batch = sam_des$batch) # to define the variable of interest
head(col_data)
```
```{r}
all(colnames(all_counts) == col_data$name) # to check the dimensions
```
## 3.10 Construct DESeqDataSet object using count data and sample description
```{r}
library(DESeq2) # firstly, we need to load the DESeq2 library
```
```{r}
dds <- DESeqDataSetFromMatrix(countData = all_counts, colData = col_data, design =~ condition) # we create the DESeq object
dds #we run it
```
## 3.11. Perform rlog and VST transformation on the data
Both transformations produce transformed data on the log2 scale which has been normalized with respect to library size or other normalization factors.
LOG TRANSFORMATION
```{r,eval=TRUE,echo=TRUE}

# Regularized log transformation
rld <- rlog(dds)
class(rld)

# Get rld in count format
rld_counts <- assay(rld)
class(rld_counts)
```
VST
```{r,eval=TRUE,echo=TRUE}

# Regularized log transformation
vsd <- varianceStabilizingTransformation(dds)
class(vsd)

# Get rld in count format
vsd_counts <- assay(vsd)
class(vsd_counts)
```

## 3.12. Draw a heatmap of count matrix based on the top 40 highly expressed genes using rlog and VST data. 
```{r}
# Load pheatmap library
library("pheatmap")

# Get normalized counts - 40 higher expressed
select <- order(rowMeans(rld_counts), decreasing = TRUE)[1:40]
head(select)
```
```{r}
# Heatmap of the rlog transformed data
pheatmap(assay(rld)[select, ])
```
```{r}
# Heatmap of the vst transformed data
pheatmap(assay(vsd)[select, ])
```


## 3.13. Generate a Sample Distance Matrix (SDM) to see the clustering of count data.

```{r}
# Compute SDM from rlog transformed data
sample_dist <- dist(t(assay(rld)))
class(sample_dist)

# Get SDM in matrix form
sdm <- as.matrix(sample_dist)
class(sdm)

# Load library
library("RColorBrewer")

# Add row names for clear plot
rownames(sdm) <- rld$Group
colnames(sdm) <- NULL

# Add colors
colors <- colorRampPalette(rev(brewer.pal(9, "Purples")))(255)

# Plot heatmap
pheatmap(sdm,
         clustering_distance_rows = sample_dist,
         clustering_distance_cols = sample_dist,
         col = colors)
```
```{r}
# Compute SDM from vst transformed data
sample_dist <- dist(t(assay(vsd)))
class(sample_dist)

# Get SDM in matrix form
sdm <- as.matrix(sample_dist)
class(sdm)

# Load library
library("RColorBrewer")

# Add row names for clear plot
rownames(sdm) <- rld$Group
colnames(sdm) <- NULL

# Add colors
colors <- colorRampPalette(rev(brewer.pal(9, "Greens")))(255)

# Plot heatmap
pheatmap(sdm,
         clustering_distance_rows = sample_dist,
         clustering_distance_cols = sample_dist,
         col = colors)
```


## 3.14. Perform the Principal Component Analysis (PCA) using rlog method and find out the % significance values of first two principal components.

```{r}
# PCA plot on our rld transformed data
plotPCA(rld, intgroup = "condition")

# Save figure
library(ggplot2)
ggsave(file = "figures/PCA_plot_rld.png")
```
Answer: the first two PC have a significance value of 70% and 13%, respectively

## 3.15. Repeat the PCA, this time using VST method and compare the plots with the ones obtained using rlog method.
```{r}
# PCA plot on our vsd transformed data
plotPCA(vsd, intgroup = "condition")

# Save figure
library(ggplot2)
ggsave(file = "figures/PCA_plot_vsd.png")
```
Answer: they significance value % change slightly in both PC, but not significantly.

# ChIP-Seq ASSESSMENT
First, we go to the right folder where our data is.
```{r,eval=F} 
setwd("~/MASTER/Advanced bioinformatics/ASSIGNMENT/ChIPseq")
getwd()
```
## 3.16. Read in the two Myc Mel peakset replicates and create the common peakset

```{r}
#Firstly, we need to create GRange objects to work with our peaks in R
melPeak_Rep1 <- read.delim("~/MASTER/Advanced bioinformatics/ASSIGNMENT/ChIPseq/mycmelrep1_peaks.xls", sep="\t", comment.char = "#")
melRep1_GR <- GRanges(seqnames=melPeak_Rep1[,"chr"], IRanges(melPeak_Rep1[,"start"], melPeak_Rep1[,"end"]))
mcols(melRep1_GR) <- melPeak_Rep1[,c("abs_summit", "fold_enrichment")]
melRep1_GR

melPeak_Rep2 <- read.delim("~/MASTER/Advanced bioinformatics/ASSIGNMENT/ChIPseq/mycmelrep2_peaks.xls", sep="\t", comment.char = "#")
melRep2_GR <- GRanges(seqnames=melPeak_Rep2[,"chr"], IRanges(melPeak_Rep2[,"start"], melPeak_Rep2[,"end"]))
mcols(melRep2_GR) <- melPeak_Rep2[,c("abs_summit", "fold_enrichment")]
melRep2_GR
```
Now, we create an object that contains all the peaks from both datasets. It is important to avoid overlapping peaks so they appear just once.

```{r}
commonMelPeaks <- melRep1_GR[melRep1_GR %over% melRep2_GR]
commonMelPeaks
```

## 3.17. Now we can rank them by their fold enrichment, select the top 500 peaks and resize these peaks to 200bp around centre.

```{r}
ordered_commonMelPeaks <- commonMelPeaks[order(commonMelPeaks$fold_enrichment,decreasing=TRUE),][1:500]
ordered_commonMelPeaks
```

```{r}
library(chipseq)
finalCommonPeaks <-  resize(ordered_commonMelPeaks, 200, fix = "center") # we want our reads to have a length of 200bp around the center, which would be the equivalent of +/- 100bp from the center position
finalCommonPeaks
```
## 3.18. Extract the sequences underneath the file and write them to FASTA file in you working directory. Inspect the file in notepad.
```{r}
library(BSgenome)
library(BSgenome.Mmusculus.UCSC.mm9)
genome <- BSgenome.Mmusculus.UCSC.mm9
seqlevelsStyle(finalCommonPeaks) <- "UCSC"
```

To get the sequences under the peaks, we will need to use the getSeq function.
```{r}
commonPeaksSequences <- getSeq(genome,GRanges(finalCommonPeaks))
names(commonPeaksSequences) <- paste0("peak_",seqnames(finalCommonPeaks),"_",
                                         start(finalCommonPeaks),
                                         "-",
                                         end(finalCommonPeaks))
```

Now, we generate the FASTA file.
```{r}
writeXStringSet(commonPeaksSequences,file="consensusPeaks.fa")
```

After examining the file on notepad, we can show how a peak would be shown. For example: >peak_chr4_45966312-45966511
AGACTCAGAATGAGAGGAGTCGTAAGAGTACATCTCAAAACCTGCCCGGCTCCCACCCTGTGATACTGACGAGGCACTTC
GCCTGTGGGCCTTGTTTTCCATTCTGCGCTACGAGAGCATGGGAATGAAAGTTCGTATATTGCCATCCCGTGGCCCAGAG
CCTTCTGATGGCTTCCCACTGTGCTCAGAATCAGACCATG

Once imputing the FASTA file in Meme-ChIP, the output obtained is a list of significant motifs, clustered by similarity and ordered by E-value. The outputs, using the first one as an example, look like this:
```{r}
knitr::include_graphics("~/MASTER/Advanced bioinformatics/ASSIGNMENT/ChIPseq/Captura de pantalla.jpg")
```
The whole results output can be checked here: https://meme-suite.org/meme//opal-jobs/appMEMECHIP_5.5.216817362842741119163048/meme-chip.html


